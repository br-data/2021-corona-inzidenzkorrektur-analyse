---
title: "Analyse_Inzidenzkorrektur"
date: "`r format(Sys.time(), format='%d. %B %Y, %H:%M Uhr')`"
author: "Claudia Kohler" 
output:
  html_document:
    template: ./lib/template/template.html
    theme: null
    mathjax: null
    pandoc_args: 
      - --to=html5
    self_contained: true
    section_divs: no
    toc: true
    css: "./lib/template/style/style.css"
---


```{r setup, include=F}

knitr::opts_chunk$set(echo=F,
                      message=F,
                      warning=F,
                      attr.source=".code .infobox")

if (!require ("tidyverse")) {
   install.packages("tidyverse")
   library(tidyverse)
}
  
if (!require ("lubridate")) {
   install.packages("lubridate")
   library(lubridate)
}

if (!require ("dplyr")) {
   install.packages("dplyr")
   library(dplyr)
}

# Load colors, ggplot2 config...
source("./lib/template/style/style.R")

```

## Über die Analyse

Diese Analyse beschäftigt sich mit den Covid-19-Fallzahl-Daten, die seit Beginn der Corona-Pandemie im Januar 2020 in Deutschland vom Robert-Koch-Institut gesammelt werden. Seit Mai 2020 wird aus diesen Daten die 7-Tage-Inzidenz für Covid-Fälle auf Ebene deutschen Landkreise und kreisfreien Städte berechnet:

7-Tage-Inzidenz = 7-Tage-Fallzahl (nach Meldedatum) / Bevölkerung eines Landkreises * 100.000

Dieser Wert gilt seitdem als Messgröße für regionales Infektionsgeschehen, seit November 2020 steht er als Indikator für die Ergreifung von Maßnahmen gegen die Ausbreitung von covid-19 im deutschen Infektionsschutzgesetz.

Die Fallmeldungen, de täglich beim RKI eingehen, sind, besonders für die jüngsten Tage, häufig zu niedrig - sie können rückblickend durch Nachmeldungen korrigiert werden. Allerdings sind diese korrigierten Zahlen, aus denen sich auch korrigierte Inzidenzwerte errechnen lassen, nicht maßgeblich für die Corona-Regelungen.

Hier soll gezeigt werden, wie groß die Auwirkungen der Meldeverzögerung rückblickend auf die Inzidenzen ist und welche Konsequenzen das für Grenzwerte haben kann.

## Über die Daten

Das RKI ergänzt den Datensatz der Covid-19-Fallmeldungen täglich um die neu gemeldeten Fälle nach Meldedatum. Michael Kreil hat für "ARD Data" diesen Datensatz täglich archiviert, sodass die Fallzahlen und Inzidenzen für einen bestimmten Tag mit den Datenständen verschiedener Tage betrachtet werden können.

Mit dem im Repo gespeicherten Script wird auf dieses Archiv zugegriffen und die 7-Tage-Fallzahlen für jede Kombination aus Übertragungsdatum, Meldedatum und Landkreis seit dem 1. Januar 2021 aggregiert. Die entsprechende csv.-Datei liegt, ebenso wie eine csv mit den Bevölkerungs- und Geodaten der Landkreise im Ordner input.

## Analyse

### Einlesen

Die beiden vorbereiteten csv-Dateien werden eingelesen. Der Zeitraum wird ausgewählt -> Start= 2021-03-01

-> nicht vergessen, eventuell Berlin loswerden


```{r}

data <- read_csv("./input/matrix_fallzahlen_7tage.csv")
data_faelle <- read_csv("./input/matrix_fallzahlen_datenstand.csv")
kreise <- read_csv("./input/Kreise-Dtl-2019.csv")

data$datenstand <- ymd(data$datenstand)
data$tag_nach_meldezeitraum <- ymd(data$tag_nach_meldezeitraum)
data$faelle <- ymd(data$datenstand)

data <- data %>% filter(datenstand >= "2021-03-01" & tag_nach_meldezeitraum >= "2021-03-01")
data_faelle <- data_faelle %>% filter(datenstand >= "2021-03-01")



```


### 7-Tage-Inzidenz berechnen

Maßgeblich für die Analyse ist der Vergleich der Inzidenzwerte der Landkreise -> Berechnung der Werte aus den 7-Tage-Fallzahlen und der Bevölkerungsinformation aus der Kreise-Datei

Formel: 7-Tage-Fallzahl / Einwohnerzahl *100.000


```{r}
ags <- kreise$Ags
data_inz <- data %>% select(c(datenstand,tag_nach_meldezeitraum)) 

for(i in 1:length(ags)) {
  
  col = ags[i]
  
  data_new <- data %>% select(c(datenstand,tag_nach_meldezeitraum,col))
  names(data_new)[3] <- "fallzahl"
  
  
  kreis <- kreise %>% filter(., ags == col)
  pop <- as.numeric(kreis[,8])
  
  data_new <- data_new %>% mutate(., inz = (fallzahl/pop*100000))%>% select(c(datenstand,tag_nach_meldezeitraum,inz))
  names(data_new)[3] <- col
  
  data_inz <- inner_join(data_inz,data_new, by = c("datenstand"="datenstand","tag_nach_meldezeitraum"="tag_nach_meldezeitraum"))
  
}

data_inz <- data_inz %>% mutate_if(is.numeric, function (x) round(x, 1))



```


```{r fig.width=10}
rki_namen <- kreise %>% select(.,c("Ags","Rkiname") )
data_long <- data_inz %>% pivot_longer(names_to = "Ags", values_to = "Inzidenz", 3:414) %>%
             mutate(weekday = lubridate::wday(tag_nach_meldezeitraum, label=TRUE)) %>%
             left_join(., rki_namen, by = "Ags")

data_faelle_l <- data_faelle %>% pivot_longer(names_to = "Ags", values_to = "Fallzahl", 2:413) %>%
             mutate(weekday = lubridate::wday(datenstand, label=TRUE)) %>%
             left_join(., rki_namen, by = "Ags")

fun <- list( mean = ~mean(.x, na.rm = TRUE), med = ~median(.x, na.rm = TRUE), max = ~max(.x, na.rm = TRUE), 
               quart = ~quantile(.x, probs = 0.75, na.rm = TRUE), quant_90 = ~quantile(.x, probs = 0.9, na.rm = TRUE), 
             sd = ~sd(.x, na.rm = TRUE), mad =~mad(.x, na.rm = TRUE))
```



### Durchschnittliche Differenz nach n Tagen

Der "erste" Inzidenzwert wird für jede Kombination aus Landkreis/Stadt und Meldedatum dem entsprechenden Wert nach den Datenständen einen, zwei, drei, vier, fünf und vierzehn Tage später gegenübergestellt.

Die durchschnittlichen Abweichungen sehen wie folgt aus:

```{r fig.width=10}

######### Inzidenzen nach 1/2/3/4/5/14 Tagen

data_diff <- data_long %>% mutate(Ind = case_when((datenstand == tag_nach_meldezeitraum)  ~ "Datenstand",
                                                  (datenstand-tag_nach_meldezeitraum == 1) ~ "nach_1",
                                                  (datenstand-tag_nach_meldezeitraum == 2) ~ "nach_2",
                                                  (datenstand-tag_nach_meldezeitraum == 3) ~ "nach_3",
                                                  (datenstand-tag_nach_meldezeitraum == 4) ~ "nach_4",
                                                  (datenstand-tag_nach_meldezeitraum == 5) ~ "nach_5",
                                                  (datenstand-tag_nach_meldezeitraum == 14) ~ "nach_14")) %>%
                            filter(., !is.na(Ind)) %>%
                            select(., -datenstand) %>%
                            pivot_wider(names_from = Ind, values_from= Inzidenz ) %>%
                            mutate(., delta_1 = nach_1-Datenstand, delta_2 = nach_2-Datenstand,
                                      delta_3 = nach_3-Datenstand,delta_4 = nach_4-Datenstand,
                                      delta_5 = nach_5-Datenstand,delta_I4=nach_14-Datenstand) 

data_diff_ges <- data_diff %>% mutate(across(c(delta_1, delta_2,delta_3,delta_4,delta_5,delta_I4), abs)) %>%
                                mutate(across(c(delta_1, delta_2,delta_3,delta_4,delta_5,delta_I4), function (x) (x/Datenstand) * 100)) %>%
                                summarise(across(c(delta_1, delta_2,delta_3,delta_4, delta_5,delta_I4),fun[1:5])) %>%
                                pivot_longer(names_to = "Art", values_to = "Inz",1:30) %>%
                                mutate(zeitraum = case_when((grepl("1",Art)==TRUE)  ~ "nach_1",
                                                      (grepl("2",Art)==TRUE)  ~ "nach_2",
                                                      (grepl("3",Art)==TRUE)  ~ "nach_3",
                                                      (grepl("_4",Art,fixed =TRUE)==TRUE )  ~ "nach_4",
                                                      (grepl("5",Art)==TRUE)  ~ "nach_5",
                                                      (grepl("I4",Art,fixed =TRUE)==TRUE)  ~ "nach_I4")) %>%
                                mutate(groesse = case_when((grepl("mean",Art)==TRUE)  ~ "Mean",
                                                      (grepl("med",Art)==TRUE)  ~ "Median",
                                                      (grepl("max",Art)==TRUE)  ~ "Max",
                                                      (grepl("quart",Art)==TRUE)  ~ "Quartil",
                                                      (grepl("quant_90",Art)==TRUE)  ~ "Quantil_90"))%>%
                                mutate(Inz = round(Inz, 1)) %>%
                                select(-Art) %>%
                                pivot_wider(names_from = groesse, values_from = Inz)%>%
                                select(zeitraum, Mean, Median, Quartil, Quantil_90, Max)

data_diff_ges %>% DT::datatable(
                rownames = F,
                options = list(
                  dom = "tBp",
                  pageLength = 6,
                  autoWidth = F))


data_diff %>%
  mutate(across(c(delta_1, delta_2,delta_3,delta_4,delta_5,delta_I4), abs)) %>%
  pivot_longer(names_to = "Art",values_to= "Delta", 12:17) %>%
  ggplot(aes(x=Art,y=Delta)) +
    geom_boxplot(aes(fill=Art), outlier.alpha = 0.5, na.rm = TRUE) +
    coord_cartesian(ylim=c(0,20)) +
    theme(legend.position = "none")
```

Die durchschnittlichen Abweichungen sehen wie folgt aus:


### Histogramm der Inzidenzwerte und ihr Zusammenhang mit den resultierenden Abweichungen (nach 1 Tag)

```{r}
data_diff %>% 
  # filter(Datenstand < 305) %>%
  mutate(across(c(delta_1, delta_2,delta_3,delta_4,delta_5,delta_I4), abs)) %>% 
  ggplot() +
    geom_histogram(mapping = aes(x = Datenstand), binwidth = 10)

# data_diff %>% 
#   # filter(Datenstand < 305) %>%
#   mutate(across(c(delta_1, delta_2,delta_3,delta_4,delta_5,delta_I4), abs)) %>% 
#   count(cut_width(Datenstand, 10))

data_diff %>% 
  filter(Datenstand < 305) %>%
  mutate(across(c(delta_1, delta_2,delta_3,delta_4,delta_5,delta_I4), abs)) %>%
  mutate(across(c(delta_1, delta_2,delta_3,delta_4,delta_5,delta_I4), function (x) (x/Datenstand) * 100)) %>%
  ggplot(aes(x = Datenstand, y = delta_1)) +
    geom_boxplot(mapping = aes(group = cut_width(Datenstand, 10))) +
    # geom_boxplot(mapping = aes(group = cut_number(Datenstand, 10))) +
    stat_summary_bin(
      geom = "point",
      binwidth = 10,
      fun = "mean",
      col = "black",
      size = 3,
      shape = 24,
      fill = "orange"
    ) +
  coord_cartesian(ylim=c(0,20)) +
  theme(panel.grid.major.x = element_line(colour = "grey"))

```

### Unterschiedliche Verteilung der aboluten und der relativen Abweichung

```{r}

data_diff %>% 
  # mutate(across(c(delta_1, delta_2,delta_3,delta_4,delta_5,delta_I4), abs)) %>%
  ggplot() +
    geom_histogram(mapping = aes(x = delta_1), binwidth = 5)
    # ylim(0,750)
 

data_diff %>% 
  # mutate(across(c(delta_1, delta_2,delta_3,delta_4,delta_5,delta_I4), abs)) %>%
  mutate(across(c(delta_1, delta_2,delta_3,delta_4,delta_5,delta_I4), function (x) (x/Datenstand) * 100)) %>%
  ggplot() +
    geom_histogram(mapping = aes(x = delta_1), binwidth = 5)
    # ylim(0,500)

 


```




### Untersuchung: Welchen Einfluss haben die Abweichungen im "relevanten" Bereich?

Der obige Boxplot und auch die vorangehenden Recherchen zeigen, dass ein Grund von Abweichungen hohe Fallzahlen sein können, welche die Gesundheitsämter belasten -  Sind die Unterschiede eventuell nur in den hohen Bereichen so drastisch und im Bereich der Grenzwerte nicht ausschlaggebend? Gleichzeitig beeinflussen niedrige Abweichungen in Landkreisen mit niederigen Fallzahlen entsprehcend die Mittel. 

-> Tabelle zeigt die Abweichungen, wenn zuvor alle Fälle mit einer Startinzidenz > 200 und < 50 herausgefiltert wurden

````{r}

data_diff_rel <- data_diff %>% filter(Datenstand <= 200 & Datenstand >= 50) %>%
                                mutate(across(c(delta_1, delta_2,delta_3,delta_4,delta_5,delta_I4), abs)) %>%
                                # mutate(across(c(delta_1, delta_2,delta_3,delta_4,delta_5,delta_I4), function (x) (x/Datenstand) * 100)) %>%
                                summarise(across(c(delta_1, delta_2,delta_3,delta_4, delta_5,delta_I4),fun[1:5]))%>%
                                pivot_longer(names_to= "Art", values_to = "Inz",1:30) %>%
                                mutate(zeitraum = case_when((grepl("1",Art)==TRUE)  ~ "nach_1",
                                                      (grepl("2",Art)==TRUE)  ~ "nach_2",
                                                      (grepl("3",Art)==TRUE)  ~ "nach_3",
                                                      (grepl("_4",Art,fixed =TRUE)==TRUE )  ~ "nach_4",
                                                      (grepl("5",Art)==TRUE)  ~ "nach_5",
                                                      (grepl("I4",Art,fixed =TRUE)==TRUE)  ~ "nach_I4")) %>%
                                mutate(groesse = case_when((grepl("mean",Art)==TRUE)  ~ "Mean",
                                                      (grepl("med",Art)==TRUE)  ~ "Median",
                                                      (grepl("max",Art)==TRUE)  ~ "Max",
                                                      (grepl("quart",Art)==TRUE)  ~ "Quartil",
                                                      (grepl("quant_90",Art)==TRUE)  ~ "Quantil_90"))%>%
                                mutate(Inz = round(Inz, 1)) %>%
                                select(-Art) %>%
                                pivot_wider(names_from = groesse, values_from = Inz) %>%
                                select(zeitraum, Mean, Median, Quartil, Quantil_90, Max)
                      

data_diff_rel %>% DT::datatable(
                rownames = F,
                options = list(
                  dom = "tBp",
                  pageLength = 6,
                  autoWidth = F))


````

Das Filtern entfernt rund 6300 von rund 27.000 Einträgen (Datenstand: 5. Mai 2021). Die zusammenfassenden Größen sind alle leicht niederer, im Vergleich zur Betrachtung des gesamten Datensatzes. 

-> Indikation dafür, dass die Höhe der Inzidenz mit der Abweichung in einem schwachen Ausmaß zusammenhängt.

### Gegencheck: Wie sieht die Verteilung der gefilterten Fälle aus? Reduziert das Filtern die Datengrundlage für ein Bundesland in unverhältnismäßigem Maß

```{r}

data_diff <- data_diff %>%
                mutate(Bl = substr(Ags, 1, 2), .after= "Ags")

Keeps <- data_diff %>% filter(Datenstand <= 200 & Datenstand >= 50) %>%
          select(c(tag_nach_meldezeitraum,Bl,Rkiname,Ags))
Discards <- data_diff %>% filter(Datenstand > 200 | Datenstand < 50 ) %>%
          select(c(tag_nach_meldezeitraum,Bl,Rkiname,Ags))

Discards %>% mutate(Bl = as.numeric(Bl)) %>%
  ggplot() +
    geom_histogram(mapping = aes(x = Bl), binwidth = 1)+
  scale_x_continuous(labels=c("SH", "HH", "NI", "HB", "NW", "HE", "RP", "BW", "BY", "SL", "BE", "BB", "MV", "SN", "ST", "TH")
                     ,breaks = c(1:16))+
  ylim(0,1500)+
  ggtitle("Herausgenommene Einträge (Tag+Landkreis) pro Bundesland")

Discard_Keeps <- left_join( (Keeps %>% count(Bl)),(Discards%>% count(Bl)), by = "Bl")
Discard_Keeps <- Discard_Keeps %>% 
                  set_names(c("Nr","Keeps","Discards")) %>%
                  mutate(Bl = c("SH", "HH", "NI", "HB", "NW", "HE", "RP", "BW", "BY", "SL", "BE", "BB", "MV", "SN", "ST", "TH"),
                         .after = "Nr")%>%
                  mutate("Percentage" = (Discards/(Discards+Keeps)), .after = "Discards")%>%
                  mutate_if(is.numeric, function (x) round(x, 4))%>%
                  mutate(Percentage = scales::percent(Percentage,accuracy=0.1)) 

Discard_Keeps %>% 
  DT::datatable(extensions = c("Buttons","FixedColumns"),
                rownames = F,
                options = list(
                  dom = "tBp",
                  buttons = c("csv", "excel"),
                  pageLength = 16,scrollX = TRUE,
                  scrollCollapse = TRUE,
                  autoWidth = F))



```



### Feinere Betrachtung der Differenzen

#### Nach Bundesländern:

- Gibt es innerhalb der bereits betrachteten Indikatoren und Zeiträumen große Unterschiede zwischen den Bundesländern?

-> Um die Daten besser vergleichbar zu machen, nehmen wir auch hier die Kombinationen aus Landkreisen und Tagen heraus, bei denen die Inzidenz nach dem "ersten" Datenstand über 200 und unter 50 lag 

```{r}


data_diff_bl <- data_diff %>% # filter(Datenstand <= 200 & Datenstand >= 50) %>%
                mutate(across(c(delta_1,delta_2,delta_3,delta_4, delta_5,delta_I4), abs)) %>%
                mutate(across(c(delta_1, delta_2,delta_3,delta_4,delta_5,delta_I4), function (x) (x/Datenstand) * 100)) %>%
                group_by(Bl) %>%
                summarise(across(c(Datenstand,delta_1,delta_2,delta_3,delta_4,delta_5,delta_I4), fun[c(1,2,3,4,6,7)])) %>%
                mutate(name = c("SH", "HH", "NI", "HB", "NW", "HE", "RP", "BW", "BY", "SL", "BE", "BB", "MV", "SN", "ST", "TH"), .after = "Bl") %>%
                mutate_if(is.numeric, function (x) round(x, 1))

data_diff_bl_table <- data_diff_bl %>%
                      relocate(Bl,name,Datenstand_mean,Datenstand_med,delta_1_mean,delta_1_med,delta_2_mean,delta_2_med,
                               delta_3_mean,delta_3_med,delta_4_mean,delta_4_med,delta_5_mean,delta_5_med,
                               delta_I4_mean,delta_I4_med,Datenstand_max,delta_1_max,delta_3_max,delta_5_max,Datenstand_quart,
                               delta_1_quart,delta_3_quart,delta_5_quart,Datenstand_sd,delta_1_sd,delta_3_sd,delta_5_sd) %>%
                      select(1:28) %>%
                      rename( Inzidenz_mean = Datenstand_mean, Inzidenz_med = Datenstand_med)

data_diff_bl_table %>%
DT::datatable(extensions = c("Buttons","FixedColumns"),
                rownames = F,
                options = list(
                  dom = "tBp",
                  buttons = c("csv", "excel"),
                  pageLength = 17,scrollX = TRUE,
                  scrollCollapse = TRUE,
                  autoWidth = T))


data_diff_bl %>% 
  pivot_longer(names_to= "Tage", values_to = "Mean_Delta", c(9,15,21,27,33,39)) %>%
  ggplot(aes(x=Tage,y=Mean_Delta, group=name))+
  geom_point() +
  facet_wrap(.~name)+
  scale_x_discrete(labels= c(1,2,3,4,5,14))+
  theme(legend.position = "none")

data_diff_bl %>% 
  pivot_longer(names_to= "Tage", values_to = "Median_Delta", c(10,16,22,28,34,40)) %>%
  ggplot(aes(x=Tage,y=Median_Delta, group=name))+
  geom_point() +
  facet_wrap(.~name)+
  scale_x_discrete(labels= c(1,2,3,4,5,14))+
  theme(legend.position = "none")

data_diff_bl %>% 
  pivot_longer(names_to= "Tage", values_to = "Quartile_Delta", c(12,18,24,30,36,42)) %>%
  ggplot(aes(x=Tage,y=Quartile_Delta, group=name))+
  geom_point() +
  facet_wrap(.~name)+
  scale_x_discrete(labels= c(1,2,3,4,5,14))+
  theme(legend.position = "none")


``` 

 
 
#### Nach Landkreisen:

Die Tabelle zeigt pro Landkreis den durchschnittlichen Inzidenzwert (Datenstand_mean) und die gemittelten Abweichungen nach 1,2,3,4,5 und 14 Tagen

```{r}

data_diff_lk <- data_diff %>% 
  mutate(across(c(delta_1,delta_2,delta_3,delta_4, delta_5,delta_I4), abs)) %>%
  mutate(across(c(delta_1, delta_2,delta_3,delta_4,delta_5,delta_I4), function (x) (x/Datenstand) * 100)) %>%
  group_by(Ags,Rkiname) %>%
  summarise(across(c(Datenstand,delta_1,delta_2,delta_3,delta_4,delta_5,delta_I4), fun[1:3])) %>%
  select(-c("Datenstand_med","Datenstand_max"))

data_diff_lk %>% mutate_if(is.numeric, function (x) round(x, 1)) %>%
  DT::datatable(extensions = c("Buttons","FixedColumns"),
                rownames = F,
                options = list(
                  dom = "tBp",
                  buttons = c("csv", "excel"),
                  pageLength = 7,scrollX = TRUE,
                  scrollCollapse = TRUE,
                  autoWidth = T))


data_diff_lk %>% 
  pivot_longer(names_to="Art", values_to="Delta_Med", c(5,11,17)) %>%
  ggplot(aes(x=Ags,y=Delta_Med, group=Art))+
  geom_point(aes(color=Art)) +
  facet_grid(Art~.)+
  xlab("Landkreise nach Ags") + ylab("Median_Abweichung") +
  theme(legend.position = "none") + 
  scale_x_discrete(labels = c("SH", "", "NI", "", "NW", "HE", "RP", "BW", "BY", "SL", "", "BB", "MV", "", "ST", "TH"), breaks = c("01001", "02000", "03101", "04011", "05111", "06411", "07111", "08111", "09161", "10041", "11001", "12051", "13003", "14511", "15001", "16051")) + 
  theme(panel.grid.major.x = element_line(colour = "grey"))
```

- Zum Zusammenhang zwischen Höhe des Inzidenzwert und Delta

```{r}
data_diff_lk %>%
  ggplot(aes(x = Datenstand_mean, y = delta_1_mean)) +
  geom_point(alpha = 0.4) + 
  geom_smooth(method='lm', formula= y~x) +
  theme(panel.grid.major.x = element_line(colour = "grey"))
```


#### Nach Tagen:

Wie sehen die durchschnittlichen Abweichungen im zeitlichen Verlauf aus? Gibt es einen Zusammenhang zwischen höheren Abweichungen und höheren Inzidenzwerten / Fallzahlen ?

```{r}

data_diff_d <- data_diff %>%
  mutate(across(c(delta_1,delta_2,delta_3,delta_4, delta_5,delta_I4), abs))%>%
  # mutate(across(c(delta_1, delta_2,delta_3,delta_4,delta_5,delta_I4), function (x) (x/Datenstand) * 100)) %>%
  group_by(tag_nach_meldezeitraum) %>%
  summarise(across(c(Datenstand,delta_1,delta_2,delta_3,delta_4, delta_5,delta_I4), fun[1:3])) %>%
  ungroup()

data_faelle_d <- data_faelle_l %>% 
                 group_by(datenstand) %>%
                 summarise(across(Fallzahl,median))%>%
                 set_names("tag_nach_meldezeitraum","Fallzahl_Med")%>%
                 ungroup

data_d_comb <- data_diff_d %>%
  select(c(1,6))%>%
  left_join(., data_faelle_d, by= "tag_nach_meldezeitraum")

data_d_comb %>%
ggplot()+
  geom_col(mapping = aes(x= tag_nach_meldezeitraum, y= Fallzahl_Med/3), fill= br24_colours[11], alpha
           =5/10) +
  geom_point(aes(x=tag_nach_meldezeitraum,y=delta_1_med*10))+
  geom_smooth(aes(x=tag_nach_meldezeitraum,y=delta_1_med*10))+
  scale_x_date(labels = scales::date_format("%d.%m"), breaks = "3 days") +
  scale_y_continuous(name = "Median Fälle pro Landkreis", sec.axis = sec_axis(~./10, name = "Median Abweich. nach 1 Tag)")) +
  xlab("Tag_nach_Meldezeitraum") +
  theme(panel.grid.major.x = element_line(colour = "grey"),
        axis.text.x = element_text(angle = 90))



```

#### Nach Wochentagen

Verteilung der Abweichungen nach Wochentagen entspricht nicht der intuitiven Annahme, dass die Inzidenzen der Wochenenden stärker bereinigt werden müssen. 
Vermutung: Da es unter der Woche sehr viel mehr Fallmeldungen gibt, als am Wochenende, kommt es hier zu mehr Berichtigungen. Die Fallzahlen sind zwar am Wocheende generell (zu) niedrig - das bedeutet aber nicht, dass sie am stärksten bereinigt werden müssen.


```{r}
data_diff_wd <- data_diff %>%
  mutate(across(c(delta_1,delta_2,delta_3,delta_4, delta_5,delta_I4), abs)) %>%
  mutate(across(c(delta_1, delta_2,delta_3,delta_4,delta_5,delta_I4), function (x) (x/Datenstand) * 100)) %>%
  group_by(weekday) %>%
  summarise(across(c(delta_1,delta_2,delta_3,delta_4, delta_5,delta_I4), fun[c(1,2,4)])) %>%
  mutate(across(2:19, ~round(.x, digits = 1)))

data_diff_wd %>% 
  pivot_longer(names_to="Tage", values_to="delta_agg", c(2,3,4,8,9,10,14,15,16)) %>%
  ggplot(aes(x=weekday,y=delta_agg, group=Tage))+
  geom_point() +
  facet_wrap(.~Tage)+
  theme(legend.position = "none")


data_faelle_wd <- data_faelle_l %>%
                  group_by(weekday) %>%
                  summarise(across(Fallzahl,fun[c(1,2,4)])) %>%
                  mutate(across(2:4, ~round(.x, digits = 1)))
  

data_diff_wd_fl <- left_join(data_diff_wd, data_faelle_wd, by ="weekday") %>%
                    relocate(Fallzahl_mean,.after = "weekday")%>%
                    relocate(Fallzahl_med,.before = "delta_1_med")

data_diff_wd_fl %>% 
  DT::datatable(extensions = c("Buttons","FixedColumns"),
                rownames = F,
                options = list(
                  dom = "tBp",
                  buttons = c("csv", "excel"),
                  pageLength = 7,scrollX = TRUE,
                  scrollCollapse = TRUE,
                  autoWidth = T))


```